{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used the below keywords to filter the data\n",
    "#The following keywords can be used ['baby', 'babies', 'mother', 'sarah'] but at the risk of unneccessary data\n",
    "keywords = ['roewade','roe', 'wade', 'prolife', 'antiabortion', 'abortion', \n",
    "    'unborn', 'baby', 'conception', 'antiwomen', 'antiwoman','reproduction', 'fetal', 'birth'\n",
    "    'fetus', 'reproduction', 'reproductive', 'embryo', 'pregnant', \n",
    "    'childbirth', 'parenthood', 'motherhood', 'pregnancy', 'fourteenth amendment', '14th amendment','trimester', 'maternal',\n",
    "    'weddington', 'jane', 'wade', 'alito', 'mississippi', 'casey', 'womb']\n",
    "\n",
    "    #Note: 'baby' -> This keyword fetched more data related to Trump on all the news comments but also has data related to roe v wade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(path, keywords):\n",
    "    \n",
    "    os.chdir(path) #Required to change the current working directory\n",
    "    data = []\n",
    "    count = 0\n",
    "    # iterate through all file\n",
    "    for file in os.listdir():\n",
    "        # Check whether file is in text format or not\n",
    "        if file.endswith(\".txt\"):\n",
    "            file_path = f\"{path}/{file}\"\n",
    "            #opening each file from directory\n",
    "            with open(file_path, \"rb\") as data:\n",
    "                for line in data:\n",
    "                    count+=1\n",
    "                    dict_str = line.decode('utf-8') # converting from byte class to utf-8\n",
    "                    dict_str = ast.literal_eval(dict_str) #Evaluates the string can be parsed or not\n",
    "                    dict_str['text'] = dict_str['text'].lower() # converts the text to lowercase\n",
    "                    dict_str['text'] = dict_str['text'].translate(str.maketrans('', '', string.punctuation)) # removing punctuation \n",
    "                    if any(word in dict_str['text'].split() for word in keywords): #checking if any one of the keyword matches the string\n",
    "                        data.append(dict_str)\n",
    "    return pd.json_normalize(data)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_video(path, keywords):\n",
    "    result = []\n",
    "    #Opening the file path\n",
    "    with open(path, encoding ='utf-8', errors='ignore') as f:\n",
    "        data = json.load(f)\n",
    "        #print(len(data))\n",
    "        for i in range(len(data)): #Parsing every json object\n",
    "            data[i]['title'] = data[i]['title'].lower() # converts the text to lowercase\n",
    "            data[i]['title'] = data[i]['title'].translate(str.maketrans('', '', string.punctuation)) # removing punctuation \n",
    "            data[i]['description'] = data[i]['description'].lower() # converts the text to lowercase\n",
    "            data[i]['description'] = data[i]['description'].translate(str.maketrans('', '', string.punctuation)) # removing punctuation \n",
    "            if any(word in (data[i]['title'].split() or data[i]['description'].split()) for word in keywords): #checking if any one of the keyword matches the string in title or description\n",
    "                result.append(data[i])\n",
    "            \n",
    "    return pd.json_normalize(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_path = \"/Users/sam/Desktop/Courses/sem3/ML_politicaldata/Project/Data/cnn_parsed/jsonbyline\" #time_taken = 24m 5.9s, rows = 209966\n",
    "fox_path = \"/Users/sam/Desktop/Courses/sem3/ML_politicaldata/Project/Data/fox_parsed/jsonbyline\" #time_taken = 26m 23.6s, rows = 191532\n",
    "msnbc_path = \"/Users/sam/Desktop/Courses/sem3/ML_politicaldata/Project/Data/msnbc_parsed/jsonbyline\" #time_taken = 15m 31.1s rows = 104759\n",
    "\n",
    "dataframe = process(msnbc_path, keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_video = \"/Users/sam/Desktop/Courses/sem3/ML_politicaldata/Project/Data/CNN_video_data.json\" #time_taken = 2.9s rows = 1117\n",
    "fox_video = \"/Users/sam/Desktop/Courses/sem3/ML_politicaldata/Project/Data/FOX_video_data.json\" #time_taken = 2.6s rows = 432\n",
    "msnbc_video = \"/Users/sam/Desktop/Courses/sem3/ML_politicaldata/Project/Data/MSNBC_video_data.json\" #time_taken = 5.1s rows = 381\n",
    "\n",
    "dataframe = process_video(msnbc_video, keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_hdf('/Users/sam/Desktop/Courses/sem3/ML_politicaldata/Project/Data/csv_files/msnbc_video.hdf', key='msnbc_video_df') # converting to hdf files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use the below keys to read the respective hdf files,\n",
    "\n",
    "Comments_data\n",
    "filename: cnn_comments.hdf ->  key: df\n",
    "filename: fox_comments.hdf ->  key: fox_df\n",
    "filename: msnbc_comments.hdf ->  key: msnbc_df\n",
    "\n",
    "Filtered_Video_data\n",
    "filename: cnn_video.hdf ->  key: cnn_video_df\n",
    "filename: fox_video.hdf -> key: fox_video_df\n",
    "filename: msnbc_video.hdf -> key: msnbc_video_df\n",
    "\"\"\"\n",
    "df = pd.read_hdf('/Users/sam/Desktop/Courses/sem3/ML_politicaldata/Project/Data/csv_files/fox_comments.hdf','fox_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "3418417383af331fcbc8316060ae8874514fff1df7fef283aa38a0cc727c6ead"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
